{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from scipy.special import inv_boxcox\n",
    "from scipy.stats import skew, norm, boxcox\n",
    "import matplotlib.pyplot as plt\n",
    "from myutils import JXPP_ETA, Plot, cal_distance, PKL\n",
    " \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, HiveContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SQLContext\n",
    "import os\n",
    "import time\n",
    "def getPsyData(dt_input):\n",
    "    print(\"getting\"+dt_input+\"psyData!!!\")\n",
    "    string = 'hive -e \"' +\"select * from fdm.fdm_sl1000000003147_ql_gis_gps where dt=\"+\"'\"+dt_input+\"'\"+\";\" + '\"> psy7.txt'\n",
    "    print(string)\n",
    "    os.system(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.read_csv('prc/df_gt_sample.csv')\n",
    "df_reg = df_reg.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['distance', 'sum_skus', 'sum_volume', 'sum_weight', 'sum_price', 'club_order', 'club_total']\n",
    "# num_cols = ['sum_skus', 'sum_volume', 'sum_weight', 'sum_price', 'sum_volume_2', 'sum_weight_2', 'sum_price_2', 'driver_avg_time', 'club_order', 'club_total', 'club_finish', 'skus_finish', 'weight_finish', 'volume_finish', 'price_finish']\n",
    "# num_cols = ['club_avg_time']\n",
    "# ord_cols = ['核心团']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "num_processor = make_pipeline(StandardScaler(), SimpleImputer(strategy='mean'))\n",
    "cat_processor = OrdinalEncoder()\n",
    "linear_preprocessor = make_column_transformer((num_processor, num_cols)) # (OrdinalEncoder(), ord_cols), \n",
    "linear_preprocessor = make_column_transformer((num_processor, num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge, RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor, AdaBoostRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \n",
    "\n",
    "ridge_pipeline = make_pipeline(linear_preprocessor, Ridge())\n",
    "lasso_pipeline = make_pipeline(linear_preprocessor, Lasso())\n",
    "svr_pipeline = make_pipeline(linear_preprocessor, SVR())\n",
    "gbdt_pipeline = make_pipeline(linear_preprocessor, GradientBoostingRegressor())\n",
    "rf_pipeline = make_pipeline(linear_preprocessor, RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross_validate用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MAPE=0.87 MAE=7.57\n",
      "1 MAPE=0.87 MAE=7.57\n",
      "2 MAPE=0.87 MAE=7.56\n",
      "3 MAPE=0.90 MAE=7.57\n",
      "4 MAPE=0.91 MAE=7.57\n",
      "5 MAPE=0.91 MAE=7.57\n",
      "6 MAPE=0.91 MAE=7.57\n",
      "7 MAPE=0.91 MAE=7.57\n",
      "8 MAPE=0.91 MAE=7.57\n",
      "9 MAPE=0.91 MAE=7.57\n",
      "MAPE=0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_validate\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import KFold\n",
    "num_cols = ['distance', 'sum_skus', 'sum_volume', 'sum_weight', 'sum_price', 'club_order', 'club_total']\n",
    "X = df_reg[num_cols]\n",
    "y = df_reg['driving_time']\n",
    "y, lambda0 = boxcox(y, lmbda=None, alpha=None)\n",
    "# split_ = 51014\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2333)\n",
    "estimators = [('Ridge', ridge_pipeline), ('Lasso', lasso_pipeline), ('gbdt', gbdt_pipeline)]#, ('randomforest', rf_pipeline)]\n",
    "# estimators = [('gbdt', gbdt_pipeline)]\n",
    "stacking_regressor = StackingRegressor(estimators=estimators, final_estimator=Ridge())\n",
    "\n",
    "\n",
    "# est.fit(X_train, y_train)\n",
    "# y_pred = est.predict(X_test)\n",
    "# print('MAPE={:.2f}'.format(mean_absolute_percentage_error(inv_boxcox(y_test, lambda0), inv_boxcox(y_pred, lambda0))))\n",
    "\n",
    "for name, est in estimators: #+ [('Stacking Regressor', stacking_regressor)]:\n",
    "#     cv = KFold(n_splits=10, shuffle=False)\n",
    "    score = cross_validate(est, X, y,\n",
    "                           scoring=['neg_mean_absolute_percentage_error'],\n",
    "                           cv=10,\n",
    "                           verbose=0,\n",
    "                           return_train_score=True,\n",
    "                          return_estimator=True)\n",
    "#     print('MAPE={:.2f} std={:.2f}'.format(-np.mean(score['test_neg_mean_absolute_percentage_error']),\n",
    "#                 np.std(score['test_neg_mean_absolute_percentage_error'])))\n",
    "#     print(score['test_neg_mean_absolute_percentage_error'])\n",
    "    for j in range(10):\n",
    "        y_pred_by_one = score['estimator'][j].predict(X)\n",
    "        print(j, 'MAPE={:.2f}'.format(mean_absolute_percentage_error(inv_boxcox(y, lambda0), inv_boxcox(y_pred_by_one, lambda0))), \n",
    "             'MAE={:.2f}'.format(np.mean(np.abs(inv_boxcox(y_pred_by_one, lambda0) - inv_boxcox(y, lambda0)))))\n",
    "    \n",
    "    y_pred = cross_val_predict(est, X, y, cv=10, verbose=0)   \n",
    "#     print('MAPE={:.2f}'.format(mean_absolute_percentage_error(y, y_pred)))\n",
    "    print('MAPE={:.2f}'.format(mean_absolute_percentage_error(inv_boxcox(y, lambda0), inv_boxcox(y_pred, lambda0))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "PKL.output(score['estimator'][0], 'models/{}'.format('drive'))\n",
    "PKL.output(lambda0, 'models/{}'.format('drive_lambda0'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PySpark)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
